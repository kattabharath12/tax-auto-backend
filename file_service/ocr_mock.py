import os
import json
import re
import random
import platform
from typing import Dict, Any, Optional, List, Tuple

try:
    import pytesseract
    from PIL import Image
    import PyPDF2
    from pdf2image import convert_from_path
    import cv2
    import numpy as np
    
    # FORCE OCR to be available - override any detection issues
    OCR_AVAILABLE = True
    
    # Set Tesseract path based on platform
    if platform.system() == "Windows":
        pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
    
    print("‚úÖ OCR libraries loaded successfully - FORCED MODE")
    
except ImportError as e:
    print(f"‚ö†Ô∏è  OCR libraries not available, using mock data: {e}")
    OCR_AVAILABLE = False

class DocumentProcessor:
    def __init__(self):
        # Generic W-2 box patterns that work for ANY W-2 document
        self.w2_box_patterns = {
            'wages': [
                # Box 1: Wages, tips, other compensation - look for number after the description
                r'(?:^|\n|\s)1\s+wages[,\s]*tips[,\s]*other compensation\s*[\n\s]*(\d{1,8}(?:\.\d{2})?)',
                r'(?:^|\n)1\s+wages.*?[\n\s]+(\d{1,8}(?:\.\d{2})?)',
                r'wages[,\s]*tips[,\s]*other compensation[\s\n]*(\d{1,8}(?:\.\d{2})?)',
                # Look for number in the wages box area (after "1" and wage-related text)
                r'1\s+(?:wages|salary).*?(\d{4,8}(?:\.\d{2})?)',
                # Generic pattern for first major number after wages mention
                r'(?:wages|salary|gross pay).*?(\d{4,8}(?:\.\d{2})?)',
                # Pattern for standalone large number (likely wages)
                r'(?:^|\n)\s*(\d{4,8}(?:\.\d{2})?)\s*(?:\n|$)',
            ],
            'federal_withholding': [
                # Box 2: Federal income tax withheld
                r'(?:^|\n|\s)2\s+federal income tax withheld\s*[\n\s]*(\d{1,6}(?:\.\d{2})?)',
                r'(?:^|\n)2\s+federal.*?[\n\s]+(\d{1,6}(?:\.\d{2})?)',
                r'federal income tax withheld[\s\n]*(\d{1,6}(?:\.\d{2})?)',
                r'2\s+federal.*?(\d{1,6}(?:\.\d{2})?)',
                # Look for smaller numbers associated with federal tax
                r'(?:federal tax|fed.*withh).*?(\d{1,6}(?:\.\d{2})?)',
            ],
            'social_security_wages': [
                # Box 3: Social security wages
                r'(?:^|\n|\s)3\s+social security wages\s*[\n\s]*(\d{1,8}(?:\.\d{2})?)',
                r'(?:^|\n)3\s+social.*?[\n\s]+(\d{1,8}(?:\.\d{2})?)',
                r'social security wages[\s\n]*(\d{1,8}(?:\.\d{2})?)',
                r'3\s+social.*?(\d{1,8}(?:\.\d{2})?)',
            ],
            'social_security_withholding': [
                # Box 4: Social security tax withheld
                r'(?:^|\n|\s)4\s+social security tax withheld\s*[\n\s]*(\d{1,6}(?:\.\d{2})?)',
                r'(?:^|\n)4\s+social.*tax.*?[\n\s]+(\d{1,6}(?:\.\d{2})?)',
                r'social security tax withheld[\s\n]*(\d{1,6}(?:\.\d{2})?)',
                r'4\s+social.*tax.*?(\d{1,6}(?:\.\d{2})?)',
            ],
            'medicare_wages': [
                # Box 5: Medicare wages and tips
                r'(?:^|\n|\s)5\s+medicare wages and tips\s*[\n\s]*(\d{1,8}(?:\.\d{2})?)',
                r'(?:^|\n)5\s+medicare.*?[\n\s]+(\d{1,8}(?:\.\d{2})?)',
                r'medicare wages and tips[\s\n]*(\d{1,8}(?:\.\d{2})?)',
                r'5\s+medicare.*?(\d{1,8}(?:\.\d{2})?)',
            ],
            'medicare_withholding': [
                # Box 6: Medicare tax withheld
                r'(?:^|\n|\s)6\s+medicare tax withheld\s*[\n\s]*(\d{1,6}(?:\.\d{2})?)',
                r'(?:^|\n)6\s+medicare.*tax.*?[\n\s]+(\d{1,6}(?:\.\d{2})?)',
                r'medicare tax withheld[\s\n]*(\d{1,6}(?:\.\d{2})?)',
                r'6\s+medicare.*tax.*?(\d{1,6}(?:\.\d{2})?)',
            ],
            'state_withholding': [
                # Box 17: State income tax
                r'(?:^|\n|\s)17\s+state income tax\s*[\n\s]*(\d{1,6}(?:\.\d{2})?)',
                r'(?:^|\n)17\s+state.*?[\n\s]+(\d{1,6}(?:\.\d{2})?)',
                r'state income tax[\s\n]*(\d{1,6}(?:\.\d{2})?)',
                r'17\s+state.*?(\d{1,6}(?:\.\d{2})?)',
            ],
            'employer_name': [
                # Box c: Employer's name - look for text after employer designation
                r'c\s+employers?\s+name.*?[\n\s]+([A-Za-z][A-Za-z\s&.,\-]{2,50}?)(?:\n|\d|$)',
                r'employer\s+name.*?[\n\s]+([A-Za-z][A-Za-z\s&.,\-]{2,50}?)(?:\n|$)',
                # Look for company-like names in the document
                r'([A-Z][A-Za-z\s&]{3,30}(?:Inc|LLC|Corp|Company|Co\.|Ltd)\.?)',
                # Extract multi-word capitalized names
                r'([A-Z][a-z]+ [A-Z][a-z]+(?:\s[A-Z][a-z]+)*)',
            ],
            'employer_ein': [
                # Box b: Employer identification number - look for EIN format
                r'b\s+employer identification number.*?[\n\s]+([A-Z0-9\-]{9,12})',
                r'employer identification number.*?[\n\s]+([A-Z0-9\-]{9,12})',
                r'ein[:\s]*([A-Z0-9\-]{9,12})',
                # Standard EIN format: XX-XXXXXXX
                r'(\d{2}-\d{7})',
                # Alternative formats
                r'([A-Z]{2,4}\d{7,9})',
            ]
        }

    def extract_document_data(self, file_path: str, content_type: str) -> Dict[str, Any]:
        """Main method to extract data from uploaded documents"""
        
        print(f"üîç DEBUG: OCR_AVAILABLE = {OCR_AVAILABLE}")
        
        if not OCR_AVAILABLE:
            print("Using mock data - OCR not available")
            return self._generate_mock_data(file_path)
            
        try:
            print(f"Processing document with ENHANCED OCR: {os.path.basename(file_path)}")
            
            # Extract text from document
            extracted_text = self._extract_text_from_file(file_path, content_type)
            
            if not extracted_text or len(extracted_text.strip()) < 3:
                print("OCR extraction failed or insufficient text, using mock data")
                return self._generate_mock_data(file_path)
            
            print(f"Extracted text length: {len(extracted_text)} characters")
            
            # Clean and normalize text for better pattern matching
            normalized_text = self._normalize_text_for_w2(extracted_text)
            
            # Show sample of extracted text for debugging
            print("=== EXTRACTED TEXT SAMPLE ===")
            print(extracted_text[:500])
            print("=== END SAMPLE ===")
            
            # Determine document type
            doc_type = self._identify_document_type(normalized_text, file_path)
            print(f"Identified document type: {doc_type}")
            
            if doc_type == "W-2":
                return self._extract_w2_data_generic(normalized_text, extracted_text)
            else:
                return self._extract_generic_data(normalized_text)
                
        except Exception as e:
            print(f"OCR processing failed: {e}, falling back to mock data")
            import traceback
            traceback.print_exc()
            return self._generate_mock_data(file_path)

    def _extract_text_from_file(self, file_path: str, content_type: str) -> str:
        """Extract text using multiple methods for maximum coverage - FIXED for image PDFs"""
        all_text = ""
        
        try:
            if content_type == "application/pdf":
                print(f"Processing PDF: {file_path}")
                
                # Method 1: Direct PDF text extraction
                direct_text = ""
                try:
                    with open(file_path, 'rb') as file:
                        pdf_reader = PyPDF2.PdfReader(file)
                        for page in pdf_reader.pages:
                            page_text = page.extract_text()
                            if page_text.strip():
                                direct_text += page_text + "\n"
                    
                    if direct_text.strip():
                        print(f"‚úÖ PDF direct extraction successful: {len(direct_text)} characters")
                        all_text += "=== PDF DIRECT EXTRACTION ===\n" + direct_text + "\n"
                    else:
                        print("‚ö†Ô∏è  PDF direct extraction returned empty - trying OCR")
                        
                except Exception as e:
                    print(f"‚ùå PDF direct extraction failed: {e}")
                
                # Method 2: OCR on PDF images (ALWAYS try this for tax documents)
                print("üîÑ Attempting OCR on PDF images...")
                try:
                    # Convert PDF to images with high DPI for better OCR
                    images = convert_from_path(file_path, dpi=400, first_page=1, last_page=1)
                    print(f"üìÑ Converted PDF to {len(images)} image(s)")
                    
                    if images:
                        image = images[0]  # Process first page
                        print(f"üñºÔ∏è  Image size: {image.size}")
                        
                        # Try multiple OCR configurations for tax forms
                        ocr_configs = [
                            '--psm 6 --oem 3 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz .,\n-',
                            '--psm 4 --oem 3',
                            '--psm 6 --oem 3',
                            '--psm 12 --oem 3',
                        ]
                        
                        best_ocr_text = ""
                        best_score = 0
                        
                        for i, config in enumerate(ocr_configs):
                            try:
                                print(f"üîç Trying OCR config {i+1}: {config}")
                                ocr_text = pytesseract.image_to_string(image, config=config)
                                
                                if ocr_text.strip():
                                    score = self._score_w2_ocr_text(ocr_text)
                                    print(f"‚úÖ OCR config {i+1} result: {len(ocr_text)} chars, score: {score:.2f}")
                                    print(f"üìù Sample: {ocr_text[:100]}...")
                                    
                                    if score > best_score:
                                        best_ocr_text = ocr_text
                                        best_score = score
                                        print(f"üèÜ New best OCR result!")
                                else:
                                    print(f"‚ùå OCR config {i+1}: No text extracted")
                                    
                            except Exception as config_e:
                                print(f"‚ùå OCR config {i+1} failed: {config_e}")
                                continue
                        
                        if best_ocr_text.strip():
                            all_text += "=== OCR EXTRACTION ===\n" + best_ocr_text + "\n"
                            print(f"‚úÖ Best OCR result: {len(best_ocr_text)} characters, score: {best_score:.2f}")
                        else:
                            print("‚ùå All OCR attempts failed to extract meaningful text")
                    else:
                        print("‚ùå Failed to convert PDF to images")
                    
                except Exception as ocr_e:
                    print(f"‚ùå PDF OCR processing failed: {ocr_e}")
                    import traceback
                    traceback.print_exc()
            
            elif content_type.startswith("image/"):
                print(f"Processing image: {file_path}")
                try:
                    image = cv2.imread(file_path)
                    if image is not None:
                        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                        enhanced = cv2.equalizeHist(gray)
                        denoised = cv2.fastNlMeansDenoising(enhanced)
                        
                        ocr_text = pytesseract.image_to_string(denoised, config='--psm 6 --oem 3')
                        all_text += "=== IMAGE OCR ===\n" + ocr_text + "\n"
                        print(f"‚úÖ Image OCR: {len(ocr_text)} characters")
                    else:
                        pil_image = Image.open(file_path)
                        ocr_text = pytesseract.image_to_string(pil_image)
                        all_text += "=== PIL OCR ===\n" + ocr_text + "\n"
                        print(f"‚úÖ PIL OCR: {len(ocr_text)} characters")
                    
                except Exception as e:
                    print(f"‚ùå Image OCR failed: {e}")
        
        except Exception as e:
            print(f"‚ùå Overall text extraction error: {e}")
        
        print(f"üìä Final extracted text length: {len(all_text)} characters")
        if all_text.strip():
            print(f"üìù Text preview: {all_text[:200]}...")
        else:
            print("‚ö†Ô∏è  WARNING: No text extracted - will fall back to mock data")
        
        return all_text

    def _score_w2_ocr_text(self, text: str) -> float:
        """Score OCR text quality specifically for W-2 forms"""
        if not text.strip():
            return 0.0
        
        score = 0.0
        text_lower = text.lower()
        
        # Check for W-2 specific terms
        w2_terms = ['w-2', 'wage', 'tax', 'statement', 'withheld', 'social security', 'medicare', 'federal', 'employer', 'employee']
        found_terms = sum(1 for term in w2_terms if term in text_lower)
        score += (found_terms / len(w2_terms)) * 0.4
        
        # Check for specific W-2 box indicators
        box_terms = ['wages tips other compensation', 'federal income tax withheld', 'social security wages', 'medicare wages']
        found_boxes = sum(1 for term in box_terms if term in text_lower)
        score += (found_boxes / len(box_terms)) * 0.3
        
        # Check for numbers (tax forms have many numbers)
        numbers = re.findall(r'\d+', text)
        if len(numbers) >= 5:  # Should have multiple numbers
            score += 0.2
        
        # Check for reasonable text length
        if 100 <= len(text) <= 5000:  # Reasonable length for W-2
            score += 0.1
        
        return min(score, 1.0)

    def _normalize_text_for_w2(self, text: str) -> str:
        """Normalize text for better W-2 pattern matching"""
        # Convert to lowercase for easier matching
        normalized = text.lower()
        
        # Clean up extra whitespace
        normalized = re.sub(r'\s+', ' ', normalized)
        
        # Ensure clear separation around numbers
        normalized = re.sub(r'(\d)([a-z])', r'\1 \2', normalized)
        normalized = re.sub(r'([a-z])(\d)', r'\1 \2', normalized)
        
        # Clean up common OCR artifacts
        normalized = re.sub(r'[^\w\s\-\.,\n]', ' ', normalized)
        
        # Ensure line breaks are preserved for box structure
        normalized = re.sub(r'\n+', '\n', normalized)
        
        return normalized

    def _extract_w2_data_generic(self, normalized_text: str, original_text: str) -> Dict[str, Any]:
        """Generic W-2 data extraction that works for any W-2"""
        data = {
            "document_type": "W-2",
            "confidence": 0.0,
            "extraction_method": "Generic Pattern Matching",
            "debug_info": [],
            "field_details": {}
        }
        
        texts_to_search = [normalized_text, original_text, original_text.lower()]
        successful_extractions = 0
        total_fields = len(self.w2_box_patterns)
        
        for field, patterns in self.w2_box_patterns.items():
            best_value = None
            best_confidence = 0
            attempts = []
            
            for text_version in texts_to_search:
                for i, pattern in enumerate(patterns):
                    try:
                        matches = re.findall(pattern, text_version, re.IGNORECASE | re.MULTILINE)
                        
                        for match in matches:
                            value = match.strip() if isinstance(match, str) else str(match)
                            
                            if field in ['wages', 'federal_withholding', 'social_security_wages', 
                                       'social_security_withholding', 'medicare_wages', 'medicare_withholding', 'state_withholding']:
                                # Numeric fields
                                cleaned_value = self._clean_currency_safe(value)
                                
                                if cleaned_value is not None and 0 <= cleaned_value <= 1000000:
                                    confidence = self._calculate_field_confidence(field, cleaned_value, text_version)
                                    attempts.append({
                                        'pattern': f"Pattern {i+1}",
                                        'raw_match': value,
                                        'cleaned_value': cleaned_value,
                                        'confidence': confidence
                                    })
                                    
                                    if confidence > best_confidence:
                                        best_value = cleaned_value
                                        best_confidence = confidence
                            else:
                                # Text fields
                                if 2 <= len(value) <= 50 and not value.isdigit():
                                    confidence = 0.6 if len(value) > 5 else 0.4
                                    attempts.append({
                                        'pattern': f"Pattern {i+1}",
                                        'raw_match': value,
                                        'cleaned_value': value,
                                        'confidence': confidence
                                    })
                                    
                                    if confidence > best_confidence:
                                        best_value = value
                                        best_confidence = confidence
                    
                    except Exception as e:
                        attempts.append({
                            'pattern': f"Pattern {i+1}",
                            'error': str(e)
                        })
            
            # Store results
            if best_value is not None and best_confidence > 0.3:  # Minimum confidence threshold
                data[field] = best_value
                data['field_details'][field] = {
                    'value': best_value,
                    'confidence': best_confidence,
                    'attempts': attempts
                }
                successful_extractions += 1
                data["debug_info"].append(f"‚úÖ {field}: {best_value} (confidence: {best_confidence:.2f})")
            else:
                data["debug_info"].append(f"‚ùå {field}: No reliable extraction")
                data['field_details'][field] = {
                    'value': None,
                    'confidence': 0,
                    'attempts': attempts
                }
        
        # Set defaults for missing critical fields
        data.setdefault('wages', 0.0)
        data.setdefault('federal_withholding', 0.0)
        data.setdefault('state_withholding', 0.0)
        data.setdefault('employer_name', 'Not found')
        
        # Calculate overall confidence
        data['confidence'] = successful_extractions / total_fields if total_fields > 0 else 0
        
        print(f"\n=== W-2 EXTRACTION SUMMARY ===")
        print(f"Successful extractions: {successful_extractions}/{total_fields}")
        print(f"Overall confidence: {data['confidence']:.2f}")
        
        # Show key extracted values
        key_fields = ['wages', 'federal_withholding', 'social_security_wages', 'medicare_wages']
        for field in key_fields:
            if field in data and isinstance(data[field], (int, float)):
                print(f"{field}: ${data[field]:,.2f}")
        
        return data

    def _clean_currency_safe(self, value: str) -> Optional[float]:
        """Safely clean currency values with strict validation"""
        if not value or not isinstance(value, str):
            return None
        
        # Remove common formatting
        cleaned = re.sub(r'[$,\s]', '', value.strip())
        
        # Remove any non-numeric characters except decimal point
        cleaned = re.sub(r'[^\d.]', '', cleaned)
        
        # Handle multiple decimal points
        if cleaned.count('.') > 1:
            parts = cleaned.split('.')
            cleaned = parts[0] + '.' + ''.join(parts[1:])
        
        # Must have at least one digit
        if not re.search(r'\d', cleaned):
            return None
        
        try:
            result = float(cleaned)
            # Reasonable bounds for W-2 values
            if 0 <= result <= 10000000:
                return result
        except (ValueError, OverflowError):
            pass
        
        return None

    def _calculate_field_confidence(self, field: str, value: float, context: str) -> float:
        """Calculate confidence based on field type and value reasonableness"""
        confidence = 0.4  # Base confidence
        
        # Field-specific validation
        if field == 'wages':
            if 1000 <= value <= 500000:
                confidence += 0.4
            elif 10000 <= value <= 200000:
                confidence += 0.5  # Most common range
        elif field in ['federal_withholding', 'state_withholding']:
            if 0 <= value <= 100000:
                confidence += 0.3
            if value > 0:  # Non-zero withholding is expected
                confidence += 0.2
        elif field in ['social_security_wages', 'medicare_wages']:
            if 100 <= value <= 200000:
                confidence += 0.4
        elif field in ['social_security_withholding', 'medicare_withholding']:
            if 0 <= value <= 20000:
                confidence += 0.3
        
        # Context bonus (if found near relevant keywords)
        field_keywords = {
            'wages': ['wage', 'salary', 'gross', 'compensation'],
            'federal_withholding': ['federal', 'tax', 'withheld'],
            'social_security_wages': ['social security', 'ss wages'],
            'medicare_wages': ['medicare', 'med wages']
        }
        
        if field in field_keywords:
            for keyword in field_keywords[field]:
                if keyword in context.lower():
                    confidence += 0.1
                    break
        
        return min(confidence, 1.0)

    def _identify_document_type(self, text: str, filename: str) -> str:
        """Identify document type"""
        text_lower = text.lower()
        filename_lower = os.path.basename(filename).lower()
        
        # Check filename
        if any(keyword in filename_lower for keyword in ['w2', 'w-2']):
            return "W-2"
        
        # Check content
        w2_score = 0
        w2_indicators = ['w-2', 'wage and tax statement', 'employer identification', 
                        'federal income tax withheld', 'social security wages', 'medicare']
        
        for indicator in w2_indicators:
            if indicator in text_lower:
                w2_score += 1
        
        # Check for numbered boxes typical of W-2
        box_matches = len(re.findall(r'\b[1-9]\s+(?:wages|federal|social|medicare)', text_lower))
        w2_score += box_matches
        
        if w2_score >= 2:
            return "W-2"
        
        return "Unknown"

    def _extract_generic_data(self, text: str) -> Dict[str, Any]:
        """Extract data from unknown document types"""
        return {
            "document_type": "Unknown",
            "extracted_text": text[:500] + "..." if len(text) > 500 else text,
            "confidence": 0.3,
            "extraction_method": "Generic",
            "message": "Document type not recognized. Please verify the extracted information."
        }

    def _generate_mock_data(self, file_path: str) -> Dict[str, Any]:
        """Generate mock data when OCR fails"""
        filename = os.path.basename(file_path).lower()
        
        if "w2" in filename or "w-2" in filename:
            return {
                "document_type": "W-2",
                "employer_name": "Demo Corp Inc",
                "wages": round(random.uniform(40000, 120000), 2),
                "federal_withholding": round(random.uniform(5000, 20000), 2),
                "state_withholding": round(random.uniform(2000, 8000), 2),
                "confidence": 0.85,
                "extraction_method": "Mock",
                "note": "Mock data - OCR not available"
            }
        else:
            return {
                "document_type": "Unknown",
                "confidence": 0.5,
                "extraction_method": "Mock",
                "note": "Mock data - OCR not available"
            }

# Create global processor instance
processor = DocumentProcessor()

def extract_document_data(file_path: str, content_type: str) -> Dict[str, Any]:
    """Main function to extract real data from documents"""
    return processor.extract_document_data(file_path, content_type)
